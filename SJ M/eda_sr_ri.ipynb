{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8405c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from koeda import EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1860f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^가-힣a-z\\s]', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    # 한국어 불용어 리스트\n",
    "    stopwords = [\n",
    "        '이', '있', '하', '것', '들', '그', '되', '수', '이', '보', '않', '없', '나', '사람', '주', '아니', \n",
    "        '등', '같', '우리', '때', '년', '가', '한', '지', '대하', '오', '말', '일', '그렇', '위하', \n",
    "        '때문', '그것', '두', '말하', '알', '그러나', '받', '못하', '일', '그런', '또', '문제', '더', '사회', \n",
    "        '많', '그리고', '좋', '크', '따르', '중', '나오', '가지', '씨', '시키', '만들', '지금', '생각하', \n",
    "        '그러', '속', '하나', '집', '살', '모르', '적', '월', '데', '자신', '안', '어떤', '내', '내', '경우',\n",
    "        '명', '생각', '시간', '그녀', '다시', '이런', '앞', '보이', '번', '나', '다른', '어떻', '여자', '개',\n",
    "        '전', '들', '사실', '이렇', '점', '싶', '말', '정도', '좀', '원', '잘', '통하', '소리', '놓'\n",
    "    ]\n",
    "    # 불용어 제거\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54637182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train.csv\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# 지정된 클래스를 숫자로 인코딩\n",
    "label_dict = {\n",
    "    '협박 대화': 0,\n",
    "    '갈취 대화': 1,\n",
    "    '직장 내 괴롭힘 대화': 2,\n",
    "    '기타 괴롭힘 대화': 3\n",
    "}\n",
    "train['label_encoded'] = train['class'].map(label_dict)\n",
    "\n",
    "# Initialize EDA\n",
    "eda_sr = EDA(\n",
    "    morpheme_analyzer=\"Okt\", alpha_sr=0.3\n",
    ")\n",
    "\n",
    "eda_ri = EDA(\n",
    "    morpheme_analyzer=\"Okt\", alpha_ri=0.3\n",
    ")\n",
    "\n",
    "# Apply Synonym Replacement (SR)\n",
    "def apply_sr(text):\n",
    "    # Using `sr` instead of `synonym_replacement`\n",
    "    augmented_texts = eda_sr([text])\n",
    "    return augmented_texts[0] if augmented_texts else text\n",
    "\n",
    "train['conversation_sr'] = train['conversation'].apply(apply_sr)\n",
    "\n",
    "# Save the SR augmented dataset\n",
    "train[['idx', 'class', 'conversation_sr']].to_csv(\"train_sr.csv\", index=False)\n",
    "\n",
    "# Apply Random Insertion (RI)\n",
    "def apply_ri(text):\n",
    "    # Using `ri` instead of `random_insertion`\n",
    "    augmented_texts = eda_ri([text])\n",
    "    return augmented_texts[0] if augmented_texts else text\n",
    "\n",
    "train['conversation_ri'] = train['conversation'].apply(apply_ri)\n",
    "\n",
    "# Save the RI augmented dataset\n",
    "train[['idx', 'class', 'conversation_ri']].to_csv(\"train_ri.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e668f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Clean the synonym replaced texts\n",
    "train_sr = pd.read_csv('train_sr.csv')\n",
    "train_sr['conversation_sr_cleaned'] = train_sr['conversation_sr'].apply(clean_text)\n",
    "train_sr[['idx', 'class', 'conversation_sr_cleaned']].to_csv('train_sr_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4be66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Clean the random inserted texts\n",
    "train_ri = pd.read_csv('train_ri.csv')\n",
    "train_ri['conversation_ri_cleaned'] = train_ri['conversation_ri'].apply(clean_text)\n",
    "train_ri[['idx', 'class', 'conversation_ri_cleaned']].to_csv('train_ri_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35373c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
