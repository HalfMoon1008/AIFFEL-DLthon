{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPN/sfr6dO9dBq3Ip9PFhvK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lPq_47NR8AD5"},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, ElectraTokenizer, BertForSequenceClassification, ElectraForSequenceClassification\n","from tqdm.notebook import tqdm\n","import re\n","import torch.nn.functional as F\n","import numpy as np"]},{"cell_type":"code","source":["def clean_text(text):\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Remove special characters and numbers\n","    text = re.sub(r'[^가-힣a-z\\s]', ' ', text)\n","    # Remove extra spaces\n","    text = ' '.join(text.split())\n","    # 한국어 불용어 리스트\n","    stopwords = [\n","        '이', '있', '하', '것', '들', '그', '되', '수', '이', '보', '않', '없', '나', '사람', '주', '아니',\n","        '등', '같', '우리', '때', '년', '가', '한', '지', '대하', '오', '말', '일', '그렇', '위하',\n","        '때문', '그것', '두', '말하', '알', '그러나', '받', '못하', '일', '그런', '또', '문제', '더', '사회',\n","        '많', '그리고', '좋', '크', '따르', '중', '나오', '가지', '씨', '시키', '만들', '지금', '생각하',\n","        '그러', '속', '하나', '집', '살', '모르', '적', '월', '데', '자신', '안', '어떤', '내', '내', '경우',\n","        '명', '생각', '시간', '그녀', '다시', '이런', '앞', '보이', '번', '나', '다른', '어떻', '여자', '개',\n","        '전', '들', '사실', '이렇', '점', '싶', '말', '정도', '좀', '원', '잘', '통하', '소리', '놓'\n","    ]\n","    # 불용어 제거\n","    text = ' '.join(word for word in text.split() if word not in stopwords)\n","    return text"],"metadata":{"id":"H4u2Dhef8bBb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 로드\n","train = pd.read_csv('./data/train.csv')\n","test = pd.read_json('./data/test.json').transpose()\n","\n","# train과 test 데이터의 텍스트 열 정규화\n","train['conversation'] = train['conversation'].apply(clean_text)\n","test['text'] = test['text'].apply(clean_text)\n","\n","# 지정된 클래스를 숫자로 인코딩\n","label_dict = {\n","    '협박 대화': 0,\n","    '갈취 대화': 1,\n","    '직장 내 괴롭힘 대화': 2,\n","    '기타 괴롭힘 대화': 3\n","}\n","train['label_encoded'] = train['class'].map(label_dict)"],"metadata":{"id":"lOMtsfDH8bDg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# KLUE용 Dataset 정의\n","class KLUEDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.text = dataframe['conversation' if 'conversation' in dataframe else 'text'].tolist()\n","        self.labels = dataframe['label_encoded'].tolist() if 'label_encoded' in dataframe else [0] * len(dataframe)\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        text = str(self.text[index])\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'targets': torch.tensor(self.labels[index], dtype=torch.long)\n","        }\n","\n","# KoELECTRA용 Dataset 정의\n","class KoELECTRADataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.text = dataframe['conversation' if 'conversation' in dataframe else 'text'].tolist()\n","        self.labels = dataframe['label_encoded'].tolist() if 'label_encoded' in dataframe else [0] * len(dataframe)\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        text = str(self.text[index])\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'targets': torch.tensor(self.labels[index], dtype=torch.long)\n","        }"],"metadata":{"id":"ImME_a7k8bGI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DataLoader 설정\n","MAX_LEN = 350\n","BATCH_SIZE = 4\n","\n","klue_tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n","koelectra_tokenizer = ElectraTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\n","\n","klue_train_dataset = KLUEDataset(train, klue_tokenizer, MAX_LEN)\n","koelectra_train_dataset = KoELECTRADataset(train, koelectra_tokenizer, MAX_LEN)\n","\n","klue_train_data_loader = DataLoader(klue_train_dataset, batch_size=BATCH_SIZE)\n","koelectra_train_data_loader = DataLoader(koelectra_train_dataset, batch_size=BATCH_SIZE)\n","\n","klue_test_dataset = KLUEDataset(test, klue_tokenizer, MAX_LEN)\n","koelectra_test_dataset = KoELECTRADataset(test, koelectra_tokenizer, MAX_LEN)\n","\n","klue_test_data_loader = DataLoader(klue_test_dataset, batch_size=BATCH_SIZE)\n","koelectra_test_data_loader = DataLoader(koelectra_test_dataset, batch_size=BATCH_SIZE)"],"metadata":{"id":"O02Xi4Ub8bIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 정의\n","class KLUEClass(torch.nn.Module):\n","    def __init__(self):\n","        super(KLUEClass, self).__init__()\n","        self.l1 = BertForSequenceClassification.from_pretrained('klue/bert-base', num_labels=4)\n","\n","    def forward(self, ids, mask):\n","        output = self.l1(ids, attention_mask=mask)\n","        return output.logits\n","\n","class KoELECTRAClass(torch.nn.Module):\n","    def __init__(self):\n","        super(KoELECTRAClass, self).__init__()\n","        self.l1 = ElectraForSequenceClassification.from_pretrained('monologg/koelectra-base-v3-discriminator', num_labels=4)\n","\n","    def forward(self, ids, mask):\n","        output = self.l1(ids, attention_mask=mask)\n","        return output.logits"],"metadata":{"id":"c7PljQOA8nTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 인스턴스 생성\n","klue_model = KLUEClass()\n","klue_model.to(torch.device(\"cuda\"))\n","\n","koelectra_model = KoELECTRAClass()\n","koelectra_model.to(torch.device(\"cuda\"))\n","\n","# 손실 함수 및 최적화 함수 설정\n","loss_function = torch.nn.CrossEntropyLoss()\n","klue_optimizer = torch.optim.Adam(params=klue_model.parameters(), lr=1e-5)\n","koelectra_optimizer = torch.optim.Adam(params=koelectra_model.parameters(), lr=1e-5)"],"metadata":{"id":"utu1VXjJ8nWQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 함수 정의\n","def train(model, tokenizer, optimizer, data_loader, epoch):\n","    model.train()\n","    for _, data in tqdm(enumerate(data_loader), total=len(data_loader)):\n","        ids = data['ids'].to(torch.device(\"cuda\"), dtype=torch.long)\n","        mask = data['mask'].to(torch.device(\"cuda\"), dtype=torch.long)\n","        targets = data['targets'].to(torch.device(\"cuda\"), dtype=torch.long)\n","\n","        outputs = model(ids, mask)\n","        optimizer.zero_grad()\n","        loss = loss_function(outputs, targets)\n","        loss.backward()\n","        optimizer.step()"],"metadata":{"id":"JGhIpf8L8nYa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 실행\n","EPOCHS = 1\n","for epoch in range(EPOCHS):\n","    print(\"Training KLUE model, Epoch:\", epoch)\n","    train(klue_model, klue_tokenizer, klue_optimizer, klue_train_data_loader, epoch)\n","\n","    print(\"Training KoELECTRA model, Epoch:\", epoch)\n","    train(koelectra_model, koelectra_tokenizer, koelectra_optimizer, koelectra_train_data_loader, epoch)"],"metadata":{"id":"bzbLPjC08bKo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 확률 예측 함수 정의\n","def predict_proba(model, data_loader):\n","    model.eval()\n","    all_probs = []\n","    with torch.no_grad():\n","        for _, data in tqdm(enumerate(data_loader), total=len(data_loader)):\n","            ids = data['ids'].to(torch.device(\"cuda\"), dtype=torch.long)\n","            mask = data['mask'].to(torch.device(\"cuda\"), dtype=torch.long)\n","\n","            outputs = model(ids, mask)\n","            probs = F.softmax(outputs, dim=1)\n","            all_probs.extend(probs.cpu().numpy().tolist())\n","    return all_probs\n","\n","# 각 모델로 확률 예측 실행\n","klue_probs = predict_proba(klue_model, klue_test_data_loader)\n","koelectra_probs = predict_proba(koelectra_model, koelectra_test_data_loader)\n","\n","# KLUE 예측값을 submission.csv로 저장\n","klue_predictions = [np.argmax(prob) for prob in klue_probs]\n","klue_submission = pd.DataFrame({'file_name': test.index, 'class': klue_predictions})\n","klue_submission.to_csv('./klue_submission.csv', index=False)\n","\n","# Koelectra 예측값을 submission.csv로 저장\n","koelectra_predictions = [np.argmax(prob) for prob in koelectra_probs]\n","koelectra_submission = pd.DataFrame({'file_name': test.index, 'class': koelectra_predictions})\n","koelectra_submission.to_csv('./koelectra_submission.csv', index=False)\n","\n","# 확률을 평균내어 최종 클래스 결정\n","final_predictions = []\n","for klue_prob, k_electra_prob in zip(klue_probs, koelectra_probs):\n","    avg_prob = [(a+b)/2 for a, b in zip(klue_prob, k_electra_prob)]\n","    final_predictions.append(np.argmax(avg_prob))\n","\n","# 앙상블 결과를 submission.csv로 저장\n","ensemble_submission = pd.DataFrame({'file_name': test.index, 'class': final_predictions})\n","ensemble_submission.to_csv('./ensemble_submission.csv', index=False)"],"metadata":{"id":"3JfhvUbC8wNa"},"execution_count":null,"outputs":[]}]}